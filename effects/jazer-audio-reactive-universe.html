<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Audio Reactive Universe - JaZeR</title>
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        html,
        body {
            width: 100%;
            height: 100%;
            overflow: hidden;
            background: #000;
        }

        canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
        }

        #controls {
            position: fixed;
            top: 20px;
            left: 20px;
            color: #0ff;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            text-shadow: 0 0 10px #0ff;
            z-index: 100;
        }

        #audioControls {
            margin-top: 10px;
        }

        button {
            background: rgba(0, 255, 255, 0.2);
            border: 1px solid #0ff;
            color: #0ff;
            padding: 8px 16px;
            cursor: pointer;
            font-family: 'Courier New', monospace;
            margin-right: 10px;
            margin-top: 5px;
        }

        button:hover {
            background: rgba(0, 255, 255, 0.4);
        }

        input[type="file"] {
            display: none;
        }

        #status {
            margin-top: 10px;
            font-size: 12px;
        }

        .meter {
            width: 200px;
            height: 10px;
            background: rgba(0, 255, 255, 0.2);
            border: 1px solid #0ff;
            margin-top: 5px;
            overflow: hidden;
        }

        .meter-fill {
            height: 100%;
            background: #0ff;
            box-shadow: 0 0 10px #0ff;
            transition: width 0.05s ease;
        }
    </style>
</head>

<body>
    <canvas id="c"></canvas>

    <div id="controls">
        <div style="font-size: 18px; font-weight: bold; margin-bottom: 10px;">
            AUDIO REACTIVE UNIVERSE
        </div>

        <div id="audioControls">
            <button id="fileBtn">Load Audio File</button>
            <button id="micBtn">Use Microphone</button>
            <input type="file" id="fileInput" accept="audio/*">
        </div>

        <div id="status">
            Status: <span id="statusText">Waiting for audio...</span>
        </div>

        <div style="margin-top: 10px;">
            <div>Volume:</div>
            <div class="meter">
                <div class="meter-fill" id="volumeMeter"></div>
            </div>

            <div style="margin-top: 5px;">Bass:</div>
            <div class="meter">
                <div class="meter-fill" id="bassMeter"></div>
            </div>

            <div style="margin-top: 5px;">Mids:</div>
            <div class="meter">
                <div class="meter-fill" id="midsMeter"></div>
            </div>

            <div style="margin-top: 5px;">Highs:</div>
            <div class="meter">
                <div class="meter-fill" id="highsMeter"></div>
            </div>
        </div>

        <div style="margin-top: 10px; font-size: 11px; opacity: 0.7;">
            Beat: <span id="beatIndicator">○</span><br>
            Particles react to audio spectrum
        </div>
    </div>

    <audio id="audio" style="display: none;" controls></audio>

    <script type="module">
        import * as THREE from '../lib/Three.js';
        import { createAudioAnalyzer, AudioVisualizer, audioScale } from '../lib/engine/jazer-audio.js';
        import { createGPUParticles } from '../lib/fx/three/jazer-gpu-particles.js';
        import '../lib/engine/jazer-navigation.js';
        window.THREE = THREE;
        const canvas = document.getElementById('c');
        const audio = document.getElementById('audio');

        // Scene setup
        const scene = new THREE.Scene();
        scene.fog = new THREE.FogExp2(0x000000, 0.001);

        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.set(0, 10, 50);

        const renderer = new THREE.WebGLRenderer({ canvas, antialias: false });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));

        // Audio analyzer
        let analyzer = createAudioAnalyzer('electronic');
        let visualizer = null;
        let isAudioReady = false;

        // GPU Particles
        const particleSystem = createGPUParticles(THREE, renderer, 'galaxy', 200000);
        scene.add(particleSystem.particles);

        // Audio-reactive sphere meshes
        const spheres = [];
        const sphereCount = 5;
        for (let i = 0; i < sphereCount; i++) {
            const geometry = new THREE.IcosahedronGeometry(2 + i * 0.5, 2);
            const material = new THREE.MeshBasicMaterial({
                color: new THREE.Color().setHSL(i / sphereCount, 0.8, 0.5),
                wireframe: true,
                transparent: true,
                opacity: 0.3
            });
            const sphere = new THREE.Mesh(geometry, material);
            sphere.userData.baseScale = 1 + i * 0.2;
            sphere.userData.frequencyIndex = i;
            scene.add(sphere);
            spheres.push(sphere);
        }

        // Frequency bars (3D visualization)
        const bars = [];
        const barCount = 64;
        const barGeometry = new THREE.BoxGeometry(1, 1, 1);
        for (let i = 0; i < barCount; i++) {
            const material = new THREE.MeshBasicMaterial({
                color: new THREE.Color().setHSL(i / barCount, 0.8, 0.5),
                transparent: true,
                opacity: 0.8
            });
            const bar = new THREE.Mesh(barGeometry, material);

            const angle = (i / barCount) * Math.PI * 2;
            const radius = 30;
            bar.position.x = Math.cos(angle) * radius;
            bar.position.z = Math.sin(angle) * radius;
            bar.position.y = 0;

            bar.userData.angle = angle;
            bar.userData.radius = radius;

            scene.add(bar);
            bars.push(bar);
        }

        // File input handler
        document.getElementById('fileBtn').addEventListener('click', () => {
            document.getElementById('fileInput').click();
        });

        document.getElementById('fileInput').addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                audio.src = url;
                audio.load();

                await analyzer.initWithElement(audio);
                visualizer = new AudioVisualizer(analyzer, { barCount: barCount });

                audio.play().then(() => {
                    isAudioReady = true;
                    document.getElementById('statusText').textContent = 'Playing: ' + file.name;
                }).catch(err => {
                    console.error('Playback failed:', err);
                });
            }
        });

        // Microphone handler
        document.getElementById('micBtn').addEventListener('click', async () => {
            try {
                await analyzer.initWithMicrophone();
                visualizer = new AudioVisualizer(analyzer, { barCount: barCount });
                isAudioReady = true;
                document.getElementById('statusText').textContent = 'Microphone active';
            } catch (err) {
                document.getElementById('statusText').textContent = 'Microphone access denied';
                console.error('Microphone failed:', err);
            }
        });

        // Animation
        let time = 0;
        let lastTime = performance.now();

        function animate() {
            requestAnimationFrame(animate);

            const now = performance.now();
            const deltaTime = (now - lastTime) / 1000;
            lastTime = now;

            time += deltaTime;

            if (isAudioReady) {
                // Update audio analysis
                analyzer.update();

                // Get audio data
                const volume = analyzer.getVolumeSmooth();
                const bass = analyzer.getBass();
                const mids = analyzer.getMids();
                const highs = analyzer.getHighs();
                const isBeat = analyzer.isBeat();
                const beatStrength = analyzer.getBeatStrength();

                // Update meters
                document.getElementById('volumeMeter').style.width = (volume * 100) + '%';
                document.getElementById('bassMeter').style.width = (bass * 100) + '%';
                document.getElementById('midsMeter').style.width = (mids * 100) + '%';
                document.getElementById('highsMeter').style.width = (highs * 100) + '%';
                document.getElementById('beatIndicator').textContent = isBeat ? '●' : '○';

                // Update particles based on audio
                particleSystem.setAttractor(
                    Math.cos(time) * bass * 20,
                    mids * 15,
                    Math.sin(time) * highs * 20,
                    10 + volume * 20
                );
                particleSystem.setCurlNoise(0.3 + bass * 0.5, 2.0 + mids * 5.0);
                particleSystem.damping = 0.1 - volume * 0.05;

                // Update audio-reactive spheres
                spheres.forEach((sphere, i) => {
                    const freq = i === 0 ? bass : i === 1 ? mids : highs;
                    sphere.scale.setScalar(sphere.userData.baseScale * (1 + freq * 2));
                    sphere.rotation.x += deltaTime * (0.5 + freq);
                    sphere.rotation.y += deltaTime * (0.3 + freq * 0.5);

                    // Pulse on beat
                    if (isBeat) {
                        sphere.material.opacity = 0.6;
                    } else {
                        sphere.material.opacity = Math.max(0.3, sphere.material.opacity * 0.95);
                    }
                });

                // Update frequency bars
                if (visualizer) {
                    const freqData = visualizer.getData();
                    bars.forEach((bar, i) => {
                        const value = freqData[i] || 0;
                        const height = 1 + value * 20;
                        bar.scale.y = height;
                        bar.position.y = height / 2;

                        // Color based on frequency
                        const hue = (i / barCount + time * 0.1) % 1.0;
                        bar.material.color.setHSL(hue, 0.8, 0.4 + value * 0.3);
                    });
                }

                // Camera movement based on bass
                camera.position.y = 10 + bass * 10;
                camera.position.z = 50 - bass * 20;
            }

            // Update particle system
            particleSystem.update(deltaTime);

            // Rotate camera
            const camRadius = 50;
            camera.position.x = Math.cos(time * 0.1) * camRadius;
            camera.position.z = Math.sin(time * 0.1) * camRadius;
            camera.lookAt(0, 0, 0);

            renderer.render(scene, camera);
        }

        // Handle resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        animate();
    </script>
</body>

</html>
